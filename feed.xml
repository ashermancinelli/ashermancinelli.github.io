<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-06-13T17:05:21-07:00</updated><id>/feed.xml</id><title type="html">Asher Mancinelli</title><subtitle>C++, Compilers, Coffee</subtitle><entry><title type="html">Never Coffee - 5/10</title><link href="/never-coffee" rel="alternate" type="text/html" title="Never Coffee - 5/10" /><published>2023-06-13T00:00:00-07:00</published><updated>2023-06-13T00:00:00-07:00</updated><id>/Never-Coffee</id><content type="html" xml:base="/never-coffee"><![CDATA[<p>Not my favorite, but it might be yours.</p>

<p>The Never Coffee cafe on SW 12th and Alder is one of the nicest cafe environments I’ve found so far, with a modern feel and pastel color palette. 
They got a low score from me simply because their espresso was not my favorite - it felt a little bland, not overly fruity or dark and rich, somewhere in the middle with less flavor than I was hoping for.</p>

<p>I had their Bangarang roast, a blend of washed Kenyan, washed Peruvian, and honey-process Honduran beans, which the barista was more than happy to tell me about - they clearly care about coffee, roast in-house, and take creative steps with their drinks, but their espresso was not for me and that’s my measuring stick.</p>

<p>Other reviews of Never Coffee call out their lattes as very above-average, which seems to be the case; almost every single person I saw in the cafe in the morning I spent there chose one of their 5 unique latte flavors, and I was the only one with a doppio.</p>

<p>If you stop by, maybe try one of their lattes.</p>

<p><a href="https://nevercoffeelab.com/">Never Coffee homepage</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Not my favorite, but it might be yours.]]></summary></entry><entry><title type="html">Coava - 10/10</title><link href="/coava" rel="alternate" type="text/html" title="Coava - 10/10" /><published>2023-06-13T00:00:00-07:00</published><updated>2023-06-13T00:00:00-07:00</updated><id>/Coava</id><content type="html" xml:base="/coava"><![CDATA[<p>The first Portland coffee shop I fell in love with.</p>

<p>When I first moved to Portland, there was a Coava cafe in the same building as my apartment, on the lobby floor.
I worked from that cafe in the upstairs seating area surrounded by Monstera Deliciosas, PSU students, and speakers playing indi tracks I’d never heard before.</p>

<p>Coava espresso is the espresso I’ve consumed the most of in my life by a long shot.
It’s no surprise that it gets a perfect 10/10; fruity but not too blond, bitter but not too dark.</p>

<p>I’ll forever mourn their west-side location, but their headquarters shop on SE Main and Grand is a much nicer cafe anyways.
The seating area is home to beautiful woodworking projects from <em>Bamboo Revolution</em> with whom Coava shares a space, along with antique roasting equipment and open-air garage doors and fans (at least in the summer time).</p>

<p>For this review I had a doppio of the <em>Java Papatong</em>, a washed-process bean from Indonesia, but I’ve loved many of their other roasts:</p>

<ul>
  <li>the San Marcos,</li>
  <li>the SO Blend from the Americas and East Africa,</li>
  <li>the Darfusu washed process,</li>
  <li>the Fazenda Serra do Boné from Brazil,</li>
</ul>

<p>and plenty of others. Their roasts are all seasonal, so try whatever they have.</p>

<p><a href="https://coavacoffee.com/">Coava Website</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[The first Portland coffee shop I fell in love with.]]></summary></entry><entry><title type="html">Dummy’s Guide to VLA/VLS Arm Development</title><link href="/arm-vla-vls" rel="alternate" type="text/html" title="Dummy’s Guide to VLA/VLS Arm Development" /><published>2023-06-12T00:00:00-07:00</published><updated>2023-06-12T00:00:00-07:00</updated><id>/ARM-VLA</id><content type="html" xml:base="/arm-vla-vls"><![CDATA[<p>description</p>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>

<h2 id="title">title</h2>

<h2 id="conclusion--links">Conclusion &amp; Links</h2>

<ol>
  <li><a href="https://gcc.gnu.org/onlinedocs/gcc/Variable-Length.html">GCC VLA docs</a></li>
  <li><a href="https://www.gnu.org/software/libc/manual/html_node/Alloca-Example.html">GCC <code class="language-plaintext highlighter-rouge">alloca</code> docs</a></li>
</ol>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>]]></content><author><name></name></author><summary type="html"><![CDATA[description]]></summary></entry><entry><title type="html">Hunt for the Best Espresso in Portland</title><link href="/espresso-pdx" rel="alternate" type="text/html" title="Hunt for the Best Espresso in Portland" /><published>2023-06-11T00:00:00-07:00</published><updated>2023-06-11T00:00:00-07:00</updated><id>/Best-Espresso-In-Portland</id><content type="html" xml:base="/espresso-pdx"><![CDATA[<p>Finding the best espresso in one of the homes of 3rd-wave coffee.</p>

<h2 id="the-plan">The Plan</h2>

<p>In the spring and summer of 2023 I started a list of coffee shops to evaluate.
By the end of the summer I hope to have established a rough ranking of the best shops,
along with some honorable mentions for great shops to work from.</p>

<p>Here are some of the early contenders:</p>

<center>
  <img src="/images/coffee/courier.png" />
</center>

<p>The second shop to get a 10/10 on my arbitrary rating system blew me away.
I’m not usually a huge fan of fruity espresso, but the double-fermented Las Frutas roasted in-house was the best espresso I’ve had to date.
The columbian beans were sealed in water bags for 72 hours before another 30 hour wet-tank soak were incredible.
The roaster and barista recomended Sterling Coffee Roasters for my next espresso, so I’m hopeful that Sterling will rate pretty highly as well.</p>

<center>
  <img src="/images/coffee/ovation.png" />
</center>

<p>Ovation Coffee and Tea was the first shop to be awarded a perfect 10/10.
The location in PSU’s campus right off the North-South streetcar line has plenty of space to work and REALLY cute porcelein cups.</p>

<h2 id="behind-the-museum">Behind the Museum</h2>

<p>The Behind the Museum cafe’s beautiful floor-to-ceiling windows and Japanese pottery along the walls make for an
especially nice work environment, especially when it’s raining -
the rain rolling off those massive windows immediately puts you at ease.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Finding the best espresso in one of the homes of 3rd-wave coffee.]]></summary></entry><entry><title type="html">Understanding VLA</title><link href="/vla-c" rel="alternate" type="text/html" title="Understanding VLA" /><published>2023-06-01T00:00:00-07:00</published><updated>2023-06-01T00:00:00-07:00</updated><id>/C-VLA-Implementation</id><content type="html" xml:base="/vla-c"><![CDATA[<p>Scattered notes from learning about the implementation of VLA.</p>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>

<h2 id="what-is-vla">What is VLA?</h2>

<p>Variable-length arrays are dynamic, stack-allocated arrays.
The compiler needs to increase the stack size in the current stack frame to allocate enough space for the array.
Assuming negative stack-growth like on x86, the compiler will decrease the stack pointer sufficiently to store the array.</p>

<p>This is almost identical to <code class="language-plaintext highlighter-rouge">alloca</code>.
Both <code class="language-plaintext highlighter-rouge">alloca</code> and VLAs are essentially primitives to modify the stack pointer.</p>

<p>Eg:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Subtracts N from current stack pointer returns sp </span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">curr_sp</span> <span class="o">=</span> <span class="n">alloca</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="nf">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="c1">// equivilant to</span>
  <span class="kt">int</span> <span class="n">curr_sp</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
</code></pre></div></div>

<p><a href="https://stackoverflow.com/questions/3488821/is-alloca-completely-replaceable">One key difference between the two:</a></p>
<blockquote>
  <p>The memory alloca() returns is valid as long as the current function persists. The lifetime of the memory occupied by a VLA is valid as long as the VLA’s identifier remains in scope. You can <code class="language-plaintext highlighter-rouge">alloca</code> memory in a loop for example and use the memory outside the loop, a VLA would be gone because the identifier goes out of scope when the loop terminates.</p>
</blockquote>

<h2 id="memory-layout">Memory Layout</h2>

<p>Because the stack grows down on most platforms, the stack pointer after an <code class="language-plaintext highlighter-rouge">alloca</code> or VLA allocation but arrays are addressed sequentially upwards, the address of the first element of a VLA array (or the pointer returned by <code class="language-plaintext highlighter-rouge">alloca</code>) will be the value of the stack pointer <em>after</em> it’s modified.</p>

<center>
  <img style="background-color:#240057;" src="/images/vla/vla-stack-pointer-viz.drawio.png" />
</center>

<p>Element 0 of the array or <code class="language-plaintext highlighter-rouge">alloca</code>-allocated memory is therefore immediately above the stack pointer after allocation, and is addressed by increasing sequentially until the end of the array.
Accessing past the array will then run into previously declared stack variables.</p>

<p>When the function returns, the stack space will be available for subsequent function calls to use automatically, so there is no need to explicitly free memory allocated by VLA/<code class="language-plaintext highlighter-rouge">alloca</code>.</p>

<h2 id="examples">Examples</h2>

<p>GCC docs:</p>
<blockquote>
  <p>These arrays are declared like any other automatic arrays, but with a length that is not a constant expression. The storage is allocated at the point of declaration and deallocated when the block scope containing the declaration exits.</p>
</blockquote>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ./vla &lt;size&gt;</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">len</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
  <span class="kt">int</span> <span class="n">array</span><span class="p">[</span><span class="n">len</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">len</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Declaring the array decrements the stack pointer enough to provide memory for the array:
<!--
gcc _includes/vla/inspect-stack.c && LEN=10 IDX=4 ./a.out
--></p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdint.h&gt;</span><span class="cp">
</span>
<span class="cp">#define SAVESTACK(X) asm( "mov %%rsp, %0" : "=rm" ( X ));
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">len</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">getenv</span><span class="p">(</span><span class="s">"LEN"</span><span class="p">));</span>
  <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">getenv</span><span class="p">(</span><span class="s">"IDX"</span><span class="p">));</span>
  <span class="k">register</span> <span class="kt">uint64_t</span> <span class="n">sp0</span><span class="p">,</span> <span class="n">sp1</span><span class="p">;</span>

  <span class="n">SAVESTACK</span><span class="p">(</span><span class="n">sp0</span><span class="p">);</span>

  <span class="kt">int</span> <span class="n">vla</span><span class="p">[</span><span class="n">len</span><span class="p">];</span>

  <span class="n">SAVESTACK</span><span class="p">(</span><span class="n">sp1</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">len</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">vla</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>

  <span class="n">printf</span><span class="p">(</span><span class="s">"&amp;vla[0]: %ld</span><span class="se">\n</span><span class="s">before: %ld</span><span class="se">\n</span><span class="s">after: %ld</span><span class="se">\n</span><span class="s">diff: %ld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="o">&amp;</span><span class="n">vla</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sp0</span><span class="p">,</span> <span class="n">sp1</span><span class="p">,</span> <span class="n">sp0</span><span class="o">-</span><span class="n">sp1</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">vla</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="p">}</span>

</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-a</span>
Linux carbon 5.15.0-71-generic <span class="c">#78-Ubuntu SMP Tue Apr 18 09:00:29 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux</span>
<span class="nv">$ </span>gcc inspect-stack-vla.c <span class="o">&amp;&amp;</span> <span class="nv">LEN</span><span class="o">=</span>10 <span class="nv">IDX</span><span class="o">=</span>4 ./a.out
&amp;vla[0]: 140737151458112
before: 140737151458160
after: 140737151458112
diff: 48
</code></pre></div></div>

<p>Notice that the address stored in the stack pointer after declaring the VLA array is the same as the address of the first element of the VLA array as depicted in the diagram above.</p>

<h2 id="alloca"><code class="language-plaintext highlighter-rouge">alloca</code></h2>

<p>Instead of declaring a VLA array, we can create a pointer to memory allocated by <code class="language-plaintext highlighter-rouge">alloca</code> to produce the same effect:
<!--
gcc _includes/vla/inspect-stack-alloca.c && LEN=10 IDX=4 ./a.out
--></p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdint.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;alloca.h&gt;</span><span class="cp">
</span>
<span class="cp">#define SAVESTACK(X) asm( "mov %%rsp, %0" : "=rm" ( X ));
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">len</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">getenv</span><span class="p">(</span><span class="s">"LEN"</span><span class="p">));</span>
  <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">getenv</span><span class="p">(</span><span class="s">"IDX"</span><span class="p">));</span>
  <span class="k">register</span> <span class="kt">uint64_t</span> <span class="n">sp0</span><span class="p">,</span> <span class="n">sp1</span><span class="p">;</span>

  <span class="n">SAVESTACK</span><span class="p">(</span><span class="n">sp0</span><span class="p">);</span>

  <span class="c1">// int vla[len];</span>
  <span class="kt">int</span><span class="o">*</span> <span class="n">vla</span> <span class="o">=</span> <span class="n">alloca</span><span class="p">(</span><span class="n">len</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="n">SAVESTACK</span><span class="p">(</span><span class="n">sp1</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">len</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">vla</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>

  <span class="n">printf</span><span class="p">(</span><span class="s">"&amp;vla[0]: %ld</span><span class="se">\n</span><span class="s">before: %ld</span><span class="se">\n</span><span class="s">after: %ld</span><span class="se">\n</span><span class="s">diff: %ld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="o">&amp;</span><span class="n">vla</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sp0</span><span class="p">,</span> <span class="n">sp1</span><span class="p">,</span> <span class="n">sp0</span><span class="o">-</span><span class="n">sp1</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">vla</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="p">}</span>

</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>gcc inspect-stack-alloca.c <span class="o">&amp;&amp;</span> <span class="nv">LEN</span><span class="o">=</span>10 <span class="nv">IDX</span><span class="o">=</span>4 ./a.out
&amp;vla[0]: 140728646054592
before: 140728646054640
after: 140728646054592
diff: 48
</code></pre></div></div>

<p>Compare the GCC docs for <code class="language-plaintext highlighter-rouge">alloca</code> with that of variable length arrays and notice the similarities:</p>

<blockquote>
  <p>The function alloca supports a kind of half-dynamic allocation in which blocks are allocated dynamically but freed automatically.</p>

  <p>Allocating a block with alloca is an explicit action; you can allocate as many blocks as you wish, and compute the size at run time. But all the blocks are freed when you exit the function that alloca was called from, just as if they were automatic variables declared in that function. There is no way to free the space explicitly.</p>
</blockquote>

<h2 id="why-might-this-be-a-bad-idea">Why Might This Be a Bad Idea?</h2>

<p>The dynamic nature of VLAs means the offset of stack variables declared after the VLA into the stack frame of the function is <strong>also dynamic</strong> - which means the function will need extra instructions to calculate the address of these variables whenever they are referenced in the body of the function.</p>

<p>This <em>may</em> be a worthwhile tradeoff, but know that use of VLAs means your code may need a few extra instructions every time you use stack variables.</p>

<!--
## LLVM IR

Docs explanation of alloca:

> The ‘alloca’ instruction allocates memory on the stack frame of the currently executing function, to be automatically released when this function returns to its caller

< !--
clang -S -emit-llvm -o - _includes/vla/simple.c
-- >
```c
#include <stdlib.h>
#include <stdio.h>

/* Contrived example that uses VLA */
int main(int argc, char** argv) {
  int len = atoi(getenv("LEN"));
  int idx = atoi(getenv("IDX"));
  int vla[len];
  return vla[idx];
}

```
```llvm
@.str = private unnamed_addr constant [4 x i8] c"LEN\00", align 1
@.str.1 = private unnamed_addr constant [4 x i8] c"IDX\00", align 1

define dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i8**, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i8*, align 8
  %9 = alloca i64, align 8
  store i32 0, i32* %3, align 4
  store i32 %0, i32* %4, align 4
  store i8** %1, i8*** %5, align 8
  %10 = call i8* @getenv(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str, i64 0, i64 0)) #4
  %11 = call i32 @atoi(i8* noundef %10) #5
  store i32 %11, i32* %6, align 4
  %12 = call i8* @getenv(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0)) #4
  %13 = call i32 @atoi(i8* noundef %12) #5
  store i32 %13, i32* %7, align 4
  %14 = load i32, i32* %6, align 4
  %15 = zext i32 %14 to i64

  %16 = call i8* @llvm.stacksave()

  store i8* %16, i8** %8, align 8
  %17 = alloca i32, i64 %15, align 16
        ^^^^^^^^^^ Dynamically allocate more memory on the stack by decrementing
                   the stack pointer, giving sufficient space for the array

  store i64 %15, i64* %9, align 8
  %18 = load i32, i32* %7, align 4
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i32, i32* %17, i64 %19
  %21 = load i32, i32* %20, align 4
  store i32 %21, i32* %3, align 4
  %22 = load i8*, i8** %8, align 8
  call void @llvm.stackrestore(i8* %22)
  %23 = load i32, i32* %3, align 4
  ret i32 %23
}
```
-->

<h2 id="conclusion--links">Conclusion &amp; Links</h2>

<ol>
  <li><a href="https://gcc.gnu.org/onlinedocs/gcc/Variable-Length.html">GCC VLA docs</a></li>
  <li><a href="https://www.gnu.org/software/libc/manual/html_node/Alloca-Example.html">GCC <code class="language-plaintext highlighter-rouge">alloca</code> docs</a></li>
  <li><a href="https://llvm.org/docs/LangRef.html#alloca-instruction">LLVM IR docs for <code class="language-plaintext highlighter-rouge">alloca</code> instruction</a></li>
  <li><a href="https://llvm.org/doxygen/Instructions_8cpp_source.html">LLVM source for <code class="language-plaintext highlighter-rouge">alloca</code> instruction</a></li>
  <li><a href="https://en.cppreference.com/w/c/language/array">cppreference docs on VLA</a></li>
  <li><a href="https://www.tenouk.com/Bufferoverflowc/Bufferoverflow2a.html">Buffer overflow and stack frame visualization</a></li>
</ol>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>]]></content><author><name></name></author><category term="c++" /><summary type="html"><![CDATA[Scattered notes from learning about the implementation of VLA.]]></summary></entry><entry><title type="html">Debugging Performance in Compilers</title><link href="/comp-debug-perf" rel="alternate" type="text/html" title="Debugging Performance in Compilers" /><published>2022-12-12T00:00:00-08:00</published><updated>2022-12-12T00:00:00-08:00</updated><id>/Compiler-Perf-Debugging</id><content type="html" xml:base="/comp-debug-perf"><![CDATA[<p>Overview of how I debug performance regressions when developing a compiler.
I don’t claim this is the best way to do it, email me or tweet at me if you’ve got better ideas😉</p>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>

<h2 id="starting-point">Starting Point</h2>

<p>Compilers are very complicated and the results can be surprising.
Sometimes performance issues only show up in large scale real-world applications.
How do you go about debugging such an issue?</p>

<p>As you might expect, narrowing down the issue to be minimal and reproducible is the first task.
Ideally, we narrow the performance regression down to a single translation unit, though sometimes this isn’t enough.
For this post, we’ll assume that the bulk of the performance regression you see in your application is coming from one translation unit, and that you know which patch is causing the regression (if you don’t know which patch is causing the regression… well you can bisect the recent patches too😁).</p>

<h2 id="bisecting-the-object-files">Bisecting the Object Files</h2>

<p>Assume we have two compilers: compiler A which doesn’t have the “bad” changes (the “good” compiler), and compiler B which does (the “bad” compiler).
We’ll start by building the application with both compilers, building half of the object files with compiler A and half with compiler B.
Say we have 100 object files that are linked into the application; we’d build the first 50 with compiler A and the second 50 with compiler B.</p>

<p>If the perf regression isn’t observed after you re-link all the object files into the application, then we know the bulk of the issue is in the object files that were just built with compiler A.
We can then rebuild all the object files in the second 50 with compiler A and build object files 26-50 or 1-25 with compiler B.
In this way, we bisect all the translation units until we find the single TU with the largest impact on performance.</p>

<p>This can be really tedious and manual, but it’s not too hard to script😉.</p>

<h2 id="bisecting-the-source-file">Bisecting the Source File</h2>

<p>Now that we’ve narrowed our regression down to a single TU, our work gets a little more complicated.
We can use the same bisection process as before, but this time we’ll have to do it on a single file.
To acomplish this, we’ll have to figure out which parts of the source file depend on each other so we can break it into two new source files, one to be built with compiler A and one to be built with compiler B (all other TUs being built with the “good” compiler).</p>

<p>Depending on the situation you may create two source files, each with half of the content of the original, or maybe you’ll use the same source file but use macro guards so each compiler only builds half of the source, eg:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* includes, declarations, and global defs up here */</span>

<span class="cp">#ifdef COMPILERA
</span><span class="c1">// stuff built with the good compiler...</span>
<span class="cp">#else </span><span class="cm">/* COMPILERB */</span><span class="cp">
</span><span class="c1">// stuff built with the bad compiler...</span>
<span class="cp">#endif
</span></code></pre></div></div>

<p>You may then add <code class="language-plaintext highlighter-rouge">-DCOMPILERA</code> to the invokation of compiler A so each compiler only builds half of the TU in question.
Again, if we don’t see the perf regression, we swap the macro guards and try again.
We then have compiler B build a quarter of the original TU and have compiler A build the other 3/4ths, and see if we observe the regression, etc etc.
Ideally, at the end of this process we know exactly which function(s) are causing the regression.</p>

<h2 id="what-next">What Next?</h2>

<p>After we’ve narrowed the regression down to a function or two (🤞) things can get tricky, and very much depends on the nature of the changes that caused the regression.</p>

<p>At this point I think it’s best to ask some questions:</p>

<ul>
  <li>Was the patch in question related to a specific pass?
    <ul>
      <li>Can the effects of that pass be seen in the function(s) we found to be causing the regression?</li>
      <li>Is the regression observed when the pass is disabled?</li>
    </ul>
  </li>
  <li>Do you notice any obvious differences between the IR the compilers generate for the identified functions?
    <ul>
      <li>Can you use those differences to work backwards to the code that generated that IR?</li>
    </ul>
  </li>
  <li>If you enable lots of debugging output (like dumping all the <code class="language-plaintext highlighter-rouge">opt</code> pass remarks) and build with compilers A and B and then diff the output, are there any glaring differences? Maybe an earlier change allowed another pass (uninvolved in the patch) to perform some transformations it otherwise would not, or maybe vice-versa.</li>
</ul>

<h2 id="why-might-this-not-work">Why Might This Not Work?</h2>

<p>Sometimes the effects only occur in a short function that is always inlined, in which case you might not find a specific TU or set of functions at the root of the regression; for this reason, you might want to crank the inlining pass down as low as it goes to help you narrow down the issue.
It’s often best to use the fewest optimizations possible when debugging this sort of thing (so long as you still observe the behavior).
<!--
--></p>]]></content><author><name></name></author><category term="c++, llvm, compilers" /><summary type="html"><![CDATA[Overview of how I debug performance regressions when developing a compiler. I don’t claim this is the best way to do it, email me or tweet at me if you’ve got better ideas😉]]></summary></entry><entry><title type="html">TBAA in LLVM IR</title><link href="/llvm-tbaa" rel="alternate" type="text/html" title="TBAA in LLVM IR" /><published>2022-12-02T00:00:00-08:00</published><updated>2022-12-02T00:00:00-08:00</updated><id>/LLVM-TBAA</id><content type="html" xml:base="/llvm-tbaa"><![CDATA[<p>Overview of type-based alias analysis in LLMV IR.</p>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>

<h2 id="llvm-alias-analysis">LLVM Alias Analysis</h2>

<p>Alias analysis answers the question “do these two addresses alias each other?” with three possible responses.
Two addresses either <code class="language-plaintext highlighter-rouge">MayAlias</code>, <code class="language-plaintext highlighter-rouge">MustAlias</code>, or they do <code class="language-plaintext highlighter-rouge">NotAlias</code> (which is how they are spelled in the LLVM alias analysis api).</p>

<p>Alias analyses can take into account lots of factors (control flow, field analysis (when analyzing structures), etc), but we’re only talking about <em>type-based</em> alias analysis (TBAA).</p>

<p>TBAA leverages the rules in the type system of the given programming language to prove something about the aliasing relationship between two addresses.</p>

<h2 id="llvm-tbaa-metadata">LLVM TBAA Metadata</h2>

<div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>

<h2 id="what-is-tbaa">What is TBAA</h2>

<h2 id="links">Links</h2>

<ul>
  <li><a target="blank" href="https://llvm.org/docs/LangRef.html#tbaa-metadata">LLVM TBAA metadata docs</a></li>
  <li><a target="blank" href="https://releases.llvm.org/8.0.0/docs/AliasAnalysis.html">LLVM alias analysis docs</a></li>
  <li><a href="https://www.cs.cornell.edu/courses/cs6120/2020fa/lesson/9/" target="blank">Cornell alias analysis slides</a></li>
  <li><a target="blank" href="https://www.researchgate.net/publication/234027199_A_Formally-Verified_Alias_Analysis">Formally Verified Alias Analysis</a></li>
  <li><a href="https://stefansf.de/c-quiz/" target="blank">Type-Based Alias Analysis in C by Stephan</a></li>
  <li><a href="https://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html" target="blank">LLMV blog: What Every C Programmer Should Know by Chris Lattner</a></li>
</ul>]]></content><author><name></name></author><category term="c++, llvm, compilers" /><summary type="html"><![CDATA[Overview of type-based alias analysis in LLMV IR.]]></summary></entry><entry><title type="html">Provable Optimizations in Coq</title><link href="/prov-opt-coq" rel="alternate" type="text/html" title="Provable Optimizations in Coq" /><published>2022-10-06T00:00:00-07:00</published><updated>2022-10-06T00:00:00-07:00</updated><id>/Provable-Optimizations</id><content type="html" xml:base="/prov-opt-coq"><![CDATA[<p>Proving that optimization passes are correct with the formal verification
assistant Coq.</p>

<font size="-1">
  <em>
    These views do not in any way represent those of NVIDIA or any other organization or institution that I am professionally associated with.
    These views are entirely my own.
  </em>
</font>

<h1 id="what-is-coq">What is Coq?</h1>

<p>It’s a programming language to help the programmer prove things.</p>]]></content><author><name></name></author><category term="c++, metaprogramming" /><summary type="html"><![CDATA[Proving that optimization passes are correct with the formal verification assistant Coq.]]></summary></entry><entry><title type="html">Slaughterhouse Five</title><link href="/sl5" rel="alternate" type="text/html" title="Slaughterhouse Five" /><published>2022-05-14T00:00:00-07:00</published><updated>2022-05-14T00:00:00-07:00</updated><id>/Slaughterhouse-5</id><content type="html" xml:base="/sl5"><![CDATA[<p>Significant quotes and reflections from reading Slaughterhouse 5 by Kurt Vonnegut.</p>

<h1 id="slaughterhouse-five">Slaughterhouse Five</h1>]]></content><author><name></name></author><summary type="html"><![CDATA[Significant quotes and reflections from reading Slaughterhouse 5 by Kurt Vonnegut.]]></summary></entry><entry><title type="html">Worth Being Wrong</title><link href="/rel-wbw" rel="alternate" type="text/html" title="Worth Being Wrong" /><published>2022-05-14T00:00:00-07:00</published><updated>2022-05-14T00:00:00-07:00</updated><id>/Worth-Being-Wrong</id><content type="html" xml:base="/rel-wbw"><![CDATA[<p>What is worth living for? How much of my life should be spent to figuring out what’s technically correct when I could be using my time to help the material conditions of my neighbor?</p>

<h1 id="whats-worth-being-wrong-about">What’s Worth Being Wrong About?</h1>

<p>I was given a set of ideas to see the world through, a toolbox for interacting with ideas and experiences.
This toolbox fell short a long time ago for many reasons which won’t be enumerated here.</p>

<p>The castle of ideas was built up in my mind over many years, and in a few short years I tore many of those walls down.
Since then, I’ve been rebuilding, reconstructing, tearing down again, and rebuilding some more.
I guess this is just a dialectic - not all that special.</p>

<p>I only have so much time and energy in this life, and I can keep building and tearing down again, or I can lift my eyes to the material conditions of my neighbors.
At some point, sorting out my philosophy became less of a priority.</p>

<p>There must come a point where I’m comfortable working with the castle I’ve built, otherwise I’ll keep adding a brick here, breaking another there, and one day I’ll look around me and realize I’m in a half-built castle in a field of half-built castles, and I could have joined my neighbor in their half-built castle years ago.</p>

<blockquote>
  <p>If I know enough to know what I’m willing to risk being wrong about, what else do I need to figure out?</p>
</blockquote>

<h1 id="a-process-god">A Process God?</h1>

<p>Tripp Fuller has been instrumental in my philisophical and religious development, and is likely a large reason I still consider myself christian.</p>

<p>He gives me hope.</p>

<p>Tyson does too.</p>

<p>There are few of them, but their words go so far.</p>

<p>When I consider the God I encounter in Jesus, I think of the christian god of process theology, at least as I understand it.
If all experience that has ever been experienced were rolled up into one being, what would that being have to say?
Let’s call that being god.</p>

<blockquote>
  <p>What would God say to you?</p>
</blockquote>

<blockquote>
  <p>If God were to walk among us, who would God become?</p>
</blockquote>

<blockquote>
  <p>Who would that God shape us to be?</p>
</blockquote>

<h1 id="could-he-have-been-wrong">Could He Have Been Wrong?</h1>

<p>John Dominic Crosson’s picture of Jesus is compelling to me - we can’t look back at how 1st c people talked about Ceasar and not apply those same rules to Jesus.
If we talk about Ceasar being a god, we can talk about Jesus being God.
If we look at the Romans and consider their notion of Ceasar’s godhood as mythology, we must apply the same reasoning to Jesus.</p>

<p>This doesn’t discount the story of Jesus however.</p>

<h2 id="mythology-as-reality">Mythology as Reality</h2>

<p>The myth of Jesus has shaped all of reality to a staggering degree.
Myths shape reality more than factual information, and if that doesn’t ring true to you, you’re not paying attention.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[What is worth living for? How much of my life should be spent to figuring out what’s technically correct when I could be using my time to help the material conditions of my neighbor?]]></summary></entry></feed>